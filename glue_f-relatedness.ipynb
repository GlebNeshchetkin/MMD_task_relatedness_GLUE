{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/glebn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torch.optim as opt\n",
    "import itertools\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedEncoder(nn.Module):\n",
    "    def __init__(self, glove_matrix, elmo_dim, hidden_size, num_layers=2):\n",
    "        super(SharedEncoder, self).__init__()\n",
    "        vocab_size, glove_dim = glove_matrix.shape\n",
    "        self.glove_embedding = nn.Embedding.from_pretrained(torch.tensor(glove_matrix, dtype=torch.float), freeze=False)\n",
    "        self.elmo_dim = elmo_dim\n",
    "        self.bilstm = nn.LSTM(glove_dim + elmo_dim, hidden_size, num_layers=num_layers, bidirectional=True, batch_first=True)\n",
    "\n",
    "    def forward(self, glove_inputs, elmo_inputs, lengths):\n",
    "        glove_embedded = self.glove_embedding(glove_inputs)\n",
    "        combined_embeddings = torch.cat([glove_embedded, elmo_inputs], dim=-1)\n",
    "        packed = pack_padded_sequence(combined_embeddings, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.bilstm(packed)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        pooled = torch.max(output, dim=1)[0]\n",
    "        return pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(filepath, embedding_dim):\n",
    "    embeddings_index = {}\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            if len(values) != embedding_dim + 1:\n",
    "                continue\n",
    "            word = values[0]\n",
    "            embedding = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = embedding\n",
    "    return embeddings_index\n",
    "\n",
    "glove_filepath = './glove.840B.300d.txt'\n",
    "embedding_dim = 300\n",
    "glove_embeddings = load_glove_embeddings(glove_filepath, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(vocab, glove_embeddings, embedding_dim):\n",
    "    vocab_size = len(vocab)\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    for word, idx in vocab.items():\n",
    "        embedding_vector = glove_embeddings.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[idx] = embedding_vector\n",
    "        else:\n",
    "            embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))\n",
    "    return torch.tensor(embedding_matrix, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_options_file = './elmo_options.json'\n",
    "elmo_weight_file = './elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'\n",
    "elmo = Elmo(elmo_options_file, elmo_weight_file, num_output_representations=1, dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"balanced_datasets_2.pkl\", \"rb\") as file:\n",
    "    loaded_datasets = pickle.load(file)\n",
    "\n",
    "train_msr = loaded_datasets[\"train_msr\"]\n",
    "train_rte = loaded_datasets[\"train_rte\"]\n",
    "train_qnli = loaded_datasets[\"train_qnli\"]\n",
    "train_qqp = loaded_datasets[\"train_qqp\"]\n",
    "train_mnli = loaded_datasets[\"train_mnli\"]\n",
    "train_sst = loaded_datasets[\"train_sst\"]\n",
    "train_cola = loaded_datasets[\"train_cola\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence_with_embeddings(sentence, tokenizer, glove_embeddings, elmo):\n",
    "    tokens = tokenizer(sentence)\n",
    "    glove_vectors = []\n",
    "    for token in tokens:\n",
    "        if token in glove_embeddings:\n",
    "            glove_vectors.append(glove_embeddings[token])\n",
    "        else:\n",
    "            glove_vectors.append(np.zeros(300))\n",
    "    character_ids = batch_to_ids([tokens])\n",
    "    elmo_output = elmo(character_ids)\n",
    "    elmo_vectors = elmo_output['elmo_representations'][0].detach().numpy()[0]\n",
    "    concatenated_embeddings = np.concatenate([glove_vectors, elmo_vectors], axis=1)\n",
    "    return concatenated_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLUEDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, glove_embeddings, elmo, max_length=50):\n",
    "        self.sentences = dataframe['sentence'].values\n",
    "        self.labels = dataframe['label'].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.glove_embeddings = glove_embeddings\n",
    "        self.elmo = elmo\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]\n",
    "        label = self.labels[idx]\n",
    "        embeddings = preprocess_sentence_with_embeddings(sentence, self.tokenizer, self.glove_embeddings, self.elmo)\n",
    "        if embeddings.shape[0] > self.max_length:\n",
    "            embeddings = embeddings[:self.max_length]\n",
    "        else:\n",
    "            pad_length = self.max_length - embeddings.shape[0]\n",
    "            pad_vector = np.zeros((pad_length, embeddings.shape[1]))\n",
    "            embeddings = np.vstack([embeddings, pad_vector])\n",
    "        return {\n",
    "            'embeddings1': torch.tensor(embeddings, dtype=torch.float),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "        \n",
    "class GLUEDatasetTwoSentence(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, glove_embeddings, elmo, max_length=50):\n",
    "        self.sent1 = dataframe['sentence1'].values\n",
    "        self.sent2 = dataframe['sentence2'].values\n",
    "        self.labels = dataframe['label'].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.glove_embeddings = glove_embeddings\n",
    "        self.elmo = elmo\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sent1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence1 = self.sent1[idx]\n",
    "        sentence2 = self.sent2[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Process embeddings for both sentences\n",
    "        embeddings1 = preprocess_sentence_with_embeddings(sentence1, self.tokenizer, self.glove_embeddings, self.elmo)\n",
    "        embeddings2 = preprocess_sentence_with_embeddings(sentence2, self.tokenizer, self.glove_embeddings, self.elmo)\n",
    "\n",
    "        # Ensure max length by padding or truncating\n",
    "        embeddings1 = self._pad_or_truncate(embeddings1)\n",
    "        embeddings2 = self._pad_or_truncate(embeddings2)\n",
    "\n",
    "        # Concatenate embeddings for both sentences\n",
    "        # combined_embeddings = np.concatenate([embeddings1, embeddings2], axis=0)\n",
    "\n",
    "        return {\n",
    "            'embeddings1': torch.tensor(embeddings1, dtype=torch.float),\n",
    "            'embeddings2': torch.tensor(embeddings2, dtype=torch.float),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def _pad_or_truncate(self, embeddings):\n",
    "        if embeddings.shape[0] > self.max_length:\n",
    "            return embeddings[:self.max_length]\n",
    "        else:\n",
    "            pad_length = self.max_length - embeddings.shape[0]\n",
    "            pad_vector = np.zeros((pad_length, embeddings.shape[1]))\n",
    "            return np.vstack([embeddings, pad_vector])\n",
    "        \n",
    "class GLUEDatasetTwoSentenceSTS(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, glove_embeddings, elmo, max_length=50):\n",
    "        self.sent1 = dataframe['sentence1'].values\n",
    "        self.sent2 = dataframe['sentence2'].values\n",
    "        self.labels = dataframe['score'].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.glove_embeddings = glove_embeddings\n",
    "        self.elmo = elmo\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sent1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence1 = self.sent1[idx]\n",
    "        sentence2 = self.sent2[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Process embeddings for both sentences\n",
    "        embeddings1 = preprocess_sentence_with_embeddings(sentence1, self.tokenizer, self.glove_embeddings, self.elmo)\n",
    "        embeddings2 = preprocess_sentence_with_embeddings(sentence2, self.tokenizer, self.glove_embeddings, self.elmo)\n",
    "\n",
    "        # Ensure max length by padding or truncating\n",
    "        embeddings1 = self._pad_or_truncate(embeddings1)\n",
    "        embeddings2 = self._pad_or_truncate(embeddings2)\n",
    "\n",
    "        # Concatenate embeddings for both sentences\n",
    "        # combined_embeddings = np.concatenate([embeddings1, embeddings2], axis=0)\n",
    "\n",
    "        return {\n",
    "            'embeddings1': torch.tensor(embeddings1, dtype=torch.float),\n",
    "            'embeddings2': torch.tensor(embeddings2, dtype=torch.float),\n",
    "            'label': torch.tensor(label, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "    def _pad_or_truncate(self, embeddings):\n",
    "        if embeddings.shape[0] > self.max_length:\n",
    "            return embeddings[:self.max_length]\n",
    "        else:\n",
    "            pad_length = self.max_length - embeddings.shape[0]\n",
    "            pad_vector = np.zeros((pad_length, embeddings.shape[1]))\n",
    "            return np.vstack([embeddings, pad_vector])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLUEDatasetTest(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, glove_embeddings, elmo, max_length=50):\n",
    "        self.sentences = dataframe['sentence'].values\n",
    "        # self.labels = dataframe['label'].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.glove_embeddings = glove_embeddings\n",
    "        self.elmo = elmo\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]\n",
    "        # label = self.labels[idx]\n",
    "        embeddings = preprocess_sentence_with_embeddings(sentence, self.tokenizer, self.glove_embeddings, self.elmo)\n",
    "        if embeddings.shape[0] > self.max_length:\n",
    "            embeddings = embeddings[:self.max_length]\n",
    "        else:\n",
    "            pad_length = self.max_length - embeddings.shape[0]\n",
    "            pad_vector = np.zeros((pad_length, embeddings.shape[1]))\n",
    "            embeddings = np.vstack([embeddings, pad_vector])\n",
    "        return {\n",
    "            'embeddings1': torch.tensor(embeddings, dtype=torch.float),\n",
    "            # 'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "        \n",
    "class GLUEDatasetTwoSentenceTest(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, glove_embeddings, elmo, max_length=50):\n",
    "        self.sent1 = dataframe['sentence1'].values\n",
    "        self.sent2 = dataframe['sentence2'].values\n",
    "        # self.labels = dataframe['label'].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.glove_embeddings = glove_embeddings\n",
    "        self.elmo = elmo\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sent1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence1 = self.sent1[idx]\n",
    "        sentence2 = self.sent2[idx]\n",
    "        # label = self.labels[idx]\n",
    "\n",
    "        # Process embeddings for both sentences\n",
    "        embeddings1 = preprocess_sentence_with_embeddings(sentence1, self.tokenizer, self.glove_embeddings, self.elmo)\n",
    "        embeddings2 = preprocess_sentence_with_embeddings(sentence2, self.tokenizer, self.glove_embeddings, self.elmo)\n",
    "\n",
    "        # Ensure max length by padding or truncating\n",
    "        embeddings1 = self._pad_or_truncate(embeddings1)\n",
    "        embeddings2 = self._pad_or_truncate(embeddings2)\n",
    "\n",
    "        # Concatenate embeddings for both sentences\n",
    "        # combined_embeddings = np.concatenate([embeddings1, embeddings2], axis=0)\n",
    "\n",
    "        return {\n",
    "            'embeddings1': torch.tensor(embeddings1, dtype=torch.float),\n",
    "            'embeddings2': torch.tensor(embeddings2, dtype=torch.float),\n",
    "            # 'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def _pad_or_truncate(self, embeddings):\n",
    "        if embeddings.shape[0] > self.max_length:\n",
    "            return embeddings[:self.max_length]\n",
    "        else:\n",
    "            pad_length = self.max_length - embeddings.shape[0]\n",
    "            pad_vector = np.zeros((pad_length, embeddings.shape[1]))\n",
    "            return np.vstack([embeddings, pad_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = word_tokenize\n",
    "cola_train_dataset = GLUEDataset(train_cola, tokenizer, glove_embeddings, elmo, max_length=50)\n",
    "sst_train_dataset = GLUEDataset(train_sst, tokenizer, glove_embeddings, elmo, max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_train_dataset = GLUEDatasetTwoSentence(train_mnli, tokenizer, glove_embeddings, elmo, max_length=50)\n",
    "msr_train_dataset = GLUEDatasetTwoSentence(train_msr, tokenizer, glove_embeddings, elmo, max_length=50)\n",
    "qnli_train_dataset = GLUEDatasetTwoSentence(train_qnli, tokenizer, glove_embeddings, elmo, max_length=50)\n",
    "qqp_train_dataset = GLUEDatasetTwoSentence(train_qqp, tokenizer, glove_embeddings, elmo, max_length=50)\n",
    "rte_train_dataset = GLUEDatasetTwoSentence(train_rte, tokenizer, glove_embeddings, elmo, max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "\n",
    "cola_train_loader = DataLoader(cola_train_dataset, batch_size=20) # 8551, 268\n",
    "sst_train_loader = DataLoader(sst_train_dataset, batch_size=20) # 67349, 2105\n",
    "mnli_train_loader = DataLoader(mnli_train_dataset, batch_size=28) # 391171, 12225\n",
    "msr_train_loader = DataLoader(msr_train_dataset, batch_size=12) # 3260, 102\n",
    "qnli_train_loader = DataLoader(qnli_train_dataset, batch_size=28) # 103106, 3223\n",
    "qqp_train_loader = DataLoader(qqp_train_dataset, batch_size=28) # 363846, 11371\n",
    "rte_train_loader = DataLoader(rte_train_dataset, batch_size=12) # 78, 2489"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300 + 1024  # GloVe (300) + ELMo (1024)\n",
    "hidden_size = 1500\n",
    "num_classes_cola = 2  # Binary classification\n",
    "num_classes_sst2 = 2  # Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [09:38<00:00, 57.89s/it]\n"
     ]
    }
   ],
   "source": [
    "cola_iter = iter(cola_train_loader)\n",
    "sst_iter = iter(sst_train_loader)\n",
    "mnli_iter = iter(mnli_train_loader)\n",
    "msr_iter = iter(msr_train_loader)\n",
    "qnli_iter = iter(qnli_train_loader)\n",
    "qqp_iter = iter(qqp_train_loader)\n",
    "rte_iter = iter(rte_train_loader)\n",
    "\n",
    "# Containers to hold all embeddings\n",
    "cola_all = []\n",
    "sst_all = []\n",
    "mnli_all = []\n",
    "msr_all = []\n",
    "qnli_all = []\n",
    "qqp_all = []\n",
    "rte_all = []\n",
    "\n",
    "for step in tqdm(range(10)):  # or more steps!\n",
    "    cola_batch = next(cola_iter)\n",
    "    cola_embeddings = cola_batch['embeddings1'].to(device)  # shape: [batch_size, 50, 1324]\n",
    "    cola_labels = cola_batch['label'].to(device)\n",
    "\n",
    "    sst_batch = next(sst_iter)\n",
    "    sst_embeddings = sst_batch['embeddings1'].to(device)    # shape: [batch_size, 50, 1324]\n",
    "    sst_labels = sst_batch['label'].to(device)\n",
    "    \n",
    "    mnli_batch = next(mnli_iter)\n",
    "    mnli_embeddings = mnli_batch['embeddings1'].to(device)    # shape: [batch_size, 50, 1324]\n",
    "    mnli_labels = mnli_batch['label'].to(device)\n",
    "    \n",
    "    msr_batch = next(msr_iter)\n",
    "    msr_embeddings = msr_batch['embeddings1'].to(device)    # shape: [batch_size, 50, 1324]\n",
    "    msr_labels = msr_batch['label'].to(device)\n",
    "    \n",
    "    qnli_batch = next(qnli_iter)\n",
    "    qnli_embeddings = qnli_batch['embeddings1'].to(device)    # shape: [batch_size, 50, 1324]\n",
    "    qnli_labels = qnli_batch['label'].to(device)\n",
    "    \n",
    "    qqp_batch = next(qqp_iter)\n",
    "    qqp_embeddings = qqp_batch['embeddings1'].to(device)    # shape: [batch_size, 50, 1324]\n",
    "    qqp_labels = qqp_batch['label'].to(device)\n",
    "    \n",
    "    rte_batch = next(rte_iter)\n",
    "    rte_embeddings = rte_batch['embeddings1'].to(device)    # shape: [batch_size, 50, 1324]\n",
    "    rte_labels = rte_batch['label'].to(device)\n",
    "\n",
    "    # Flatten across time (sequence) dimension\n",
    "    cola_all.append(cola_embeddings.view(-1, 1324))  # [batch_size * 50, 1324]\n",
    "    sst_all.append(sst_embeddings.view(-1, 1324))    # same here\n",
    "    mnli_all.append(mnli_embeddings.view(-1, 1324))  # [batch_size * 50, 1324]\n",
    "    msr_all.append(msr_embeddings.view(-1, 1324))\n",
    "    qnli_all.append(qnli_embeddings.view(-1, 1324))  # [batch_size * 50, 1324]\n",
    "    qqp_all.append(qqp_embeddings.view(-1, 1324))\n",
    "    rte_all.append(rte_embeddings.view(-1, 1324))  # [batch_size * 50, 1324]\n",
    "\n",
    "# Combine into full matrices\n",
    "cola_matrix = torch.cat(cola_all, dim=0)  # shape: [total_Cola_sentences * 50, 1324]\n",
    "sst_matrix = torch.cat(sst_all, dim=0)    # shape: [total_SST_sentences * 50, 1324]\n",
    "mnli_matrix = torch.cat(mnli_all, dim=0)  # shape: [total_Cola_sentences * 50, 1324]\n",
    "msr_matrix = torch.cat(msr_all, dim=0)\n",
    "qnli_matrix = torch.cat(qnli_all, dim=0)  # shape: [total_Cola_sentences * 50, 1324]\n",
    "qqp_matrix = torch.cat(qqp_all, dim=0)\n",
    "rte_matrix = torch.cat(rte_all, dim=0)  # shape: [total_Cola_sentences * 50, 1324]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_rows = torch.nonzero(cola_matrix.abs().sum(dim=1) > 0).squeeze()\n",
    "cola_matrix = cola_matrix[non_zero_rows]\n",
    "non_zero_rows = torch.nonzero(sst_matrix.abs().sum(dim=1) > 0).squeeze()\n",
    "sst_matrix = sst_matrix[non_zero_rows]\n",
    "non_zero_rows = torch.nonzero(mnli_matrix.abs().sum(dim=1) > 0).squeeze()\n",
    "mnli_matrix = mnli_matrix[non_zero_rows]\n",
    "non_zero_rows = torch.nonzero(msr_matrix.abs().sum(dim=1) > 0).squeeze()\n",
    "msr_matrix = msr_matrix[non_zero_rows]\n",
    "non_zero_rows = torch.nonzero(qnli_matrix.abs().sum(dim=1) > 0).squeeze()\n",
    "qnli_matrix = qnli_matrix[non_zero_rows]\n",
    "non_zero_rows = torch.nonzero(qqp_matrix.abs().sum(dim=1) > 0).squeeze()\n",
    "qqp_matrix = qqp_matrix[non_zero_rows]\n",
    "non_zero_rows = torch.nonzero(rte_matrix.abs().sum(dim=1) > 0).squeeze()\n",
    "rte_matrix = rte_matrix[non_zero_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_size = min(cola_matrix.shape[0], sst_matrix.shape[0], mnli_matrix.shape[0], msr_matrix.shape[0], qnli_matrix.shape[0], qqp_matrix.shape[0], rte_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_matrix = sst_matrix[:min_size]\n",
    "cola_matrix = cola_matrix[:min_size]\n",
    "mnli_matrix = mnli_matrix[:min_size]\n",
    "msr_matrix = msr_matrix[:min_size]\n",
    "qnli_matrix = qnli_matrix[:min_size]\n",
    "qqp_matrix = qqp_matrix[:min_size]\n",
    "rte_matrix = rte_matrix[:min_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1728, 1728])\n",
      "tensor(2811537., device='cuda:0') tensor(2827945.7500, device='cuda:0') tensor(16340.8848, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2811537., device='cuda:0') tensor(2868462.2500, device='cuda:0') tensor(16455.6699, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2811537., device='cuda:0') tensor(2889557.7500, device='cuda:0') tensor(16458.8809, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2811537., device='cuda:0') tensor(2830970.2500, device='cuda:0') tensor(16258.6875, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2811537., device='cuda:0') tensor(2804926.5000, device='cuda:0') tensor(16055.9043, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2811537., device='cuda:0') tensor(2888106.5000, device='cuda:0') tensor(16397.3828, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2827945.7500, device='cuda:0') tensor(2868462.2500, device='cuda:0') tensor(16446.8398, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2827945.7500, device='cuda:0') tensor(2889557.7500, device='cuda:0') tensor(16487.6367, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2827945.7500, device='cuda:0') tensor(2830970.2500, device='cuda:0') tensor(16240.8281, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2827945.7500, device='cuda:0') tensor(2804926.5000, device='cuda:0') tensor(16055.1055, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2827945.7500, device='cuda:0') tensor(2888106.5000, device='cuda:0') tensor(16416.9414, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2868462.2500, device='cuda:0') tensor(2889557.7500, device='cuda:0') tensor(16681.3281, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2868462.2500, device='cuda:0') tensor(2830970.2500, device='cuda:0') tensor(16337.9648, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2868462.2500, device='cuda:0') tensor(2804926.5000, device='cuda:0') tensor(16097.1816, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2868462.2500, device='cuda:0') tensor(2888106.5000, device='cuda:0') tensor(16593.4531, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2889557.7500, device='cuda:0') tensor(2830970.2500, device='cuda:0') tensor(16474.3574, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2889557.7500, device='cuda:0') tensor(2804926.5000, device='cuda:0') tensor(16268.5938, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2889557.7500, device='cuda:0') tensor(2888106.5000, device='cuda:0') tensor(16663.1211, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2830970.2500, device='cuda:0') tensor(2804926.5000, device='cuda:0') tensor(16069.5938, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2830970.2500, device='cuda:0') tensor(2888106.5000, device='cuda:0') tensor(16379.0156, device='cuda:0')\n",
      "torch.Size([1728, 1728])\n",
      "tensor(2804926.5000, device='cuda:0') tensor(2888106.5000, device='cuda:0') tensor(16148.1855, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def rbf_kernel(x, y, sigma):\n",
    "    # x_norm = (x ** 2).sum(dim=1).view(-1, 1)  # Shape (m, 1)\n",
    "    # y_norm = (y ** 2).sum(dim=1).view(1, -1)  # Shape (1, n)\n",
    "    # dist = x_norm + y_norm - 2.0 * torch.mm(x, y.t())  # Shape (m, n)\n",
    "    xx=torch.mm(x,x.t())\n",
    "    yy=torch.mm(y,y.t())\n",
    "    xy=torch.mm(x,y.t())\n",
    "    return torch.exp(-(xx+yy-xy) / (2 * sigma ** 2))  # Apply Gaussian kernel\n",
    "\n",
    "def compute_mmd2(X, Y, kernel_fn, sigma_x, sigma_y, sigma_xy):\n",
    "    K_xx = kernel_fn(X, X, sigma_x)  # Shape (m, m)\n",
    "    K_yy = kernel_fn(Y, Y, sigma_y)  # Shape (n, n)\n",
    "    K_xy = kernel_fn(X, Y, sigma_xy)  # Shape (m, n)\n",
    "    \n",
    "    XX = K_xx.sum() - torch.diag(K_xx).sum()  # Sum all elements excluding diagonal\n",
    "    YY = K_yy.sum() - torch.diag(K_yy).sum()  # Sum all elements excluding diagonal\n",
    "    XY = K_xy[:10].sum()  # Sum of all off-diagonal elements\n",
    "    print(K_xy.shape)\n",
    "    \n",
    "    print(XX,YY,XY)\n",
    "    \n",
    "    m = X.shape[0]\n",
    "\n",
    "    mmd2 = XX.item()/(m*(m-1)) + YY.item()/(m*(m-1)) - 2 * XY.item()/(m*(m)) # Normalize by number of pairs\n",
    "\n",
    "    return mmd2, K_xy\n",
    "\n",
    "tasks = {\n",
    "    'sst_matrix': sst_matrix,\n",
    "    'cola_matrix': cola_matrix,\n",
    "    'mnli_matrix': mnli_matrix,\n",
    "    'msr_matrix': msr_matrix,\n",
    "    'qnli_matrix': qnli_matrix,\n",
    "    'qqp_matrix': qqp_matrix,\n",
    "    'rte_matrix': rte_matrix,\n",
    "}\n",
    "\n",
    "combinations = list(itertools.combinations(tasks.items(), 2))\n",
    "\n",
    "graph_weights = {}\n",
    "\n",
    "for (name1, mat1), (name2, mat2) in combinations:\n",
    "    \n",
    "    x_ = mat1\n",
    "    y_ = mat2\n",
    "\n",
    "    distances = torch.cdist(x_, x_, p=2) ** 2\n",
    "    median_distance = torch.median(distances[distances > 0])  # Exclude zero distances\n",
    "    sigma_x = torch.sqrt(median_distance)\n",
    "\n",
    "    distances = torch.cdist(y_, y_, p=2) ** 2\n",
    "    median_distance = torch.median(distances[distances > 0])  # Exclude zero distances\n",
    "    sigma_y = torch.sqrt(median_distance)\n",
    "\n",
    "    distances = torch.cdist(x_, y_, p=2) ** 2\n",
    "    median_distance = torch.median(distances[distances > 0])  # Exclude zero distances\n",
    "    sigma_xy = torch.sqrt(median_distance)\n",
    "\n",
    "    mmd_score, k_xy = compute_mmd2(x_, y_, rbf_kernel, sigma_x=sigma_x.item(), sigma_y=sigma_y.item(), sigma_xy=sigma_xy.item())\n",
    "    graph_weights[f\"Combining {name1} and {name2}\"] = round(mmd_score, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = nx.Graph()\n",
    "for key, weight in graph_weights.items():\n",
    "    parts = key.replace('Combining ', '').replace('_matrix', '').split(' and ')\n",
    "    task1, task2 = parts\n",
    "    G.add_edge(task1, task2, weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allennlp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
